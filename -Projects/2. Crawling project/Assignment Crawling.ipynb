{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6caadcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup as b_s\n",
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "from googleapiclient.discovery import build\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147aee8e",
   "metadata": {},
   "source": [
    "\n",
    "##### 오늘 날짜 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd0caacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-07-12-Monday'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = dt.today().strftime('%Y-%m-%d-%A')\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb1652",
   "metadata": {},
   "source": [
    "##### 오늘 날씨 출력 (네이버 크롤링)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d967182",
   "metadata": {},
   "source": [
    "    기상청이나 공공데이터 크롤링 해보신 분에게 직접 물어봐서 해보겠습니다. 제가 할땐 정말 안되더군요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f5091781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def today_weather():\n",
    "    html = requests.get('https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%82%A0%EC%94%A8')\n",
    "    soup = b_s(html.text,'html.parser')\n",
    "    Wdata = soup.find('div', {'class':'weather_box'})\n",
    "    find_lc = Wdata.find('span',{'class':'btn_select'}).text\n",
    "    print('현재위치 : '+find_lc,'℃' )\n",
    "    find_ct = Wdata.find('span',{'class':'todaytemp'}).text\n",
    "    print(\"현재온도 : \"+find_ct,'℃')\n",
    "    find_ht = Wdata.select_one('span.max>span.num').text\n",
    "    print(\"최고온도 : \"+find_ht,'℃')\n",
    "    find_lt = Wdata.select_one('span.min>span.num').text\n",
    "    print('최저온도 : '+find_lt,'℃')\n",
    "    find_ft = Wdata.select_one('span.sensible>em>span.num').text\n",
    "    print('체감온도 : '+find_ft,'℃')\n",
    "    find_dt = Wdata.select_one('div.today_area._mainTabContent > div.main_info > div > ul > li:nth-child(1) > p').text\n",
    "    print(find_dt)\n",
    "    find_am_hm = Wdata.select_one('li>span.point_time.morning>span.rain_rate>span.num').text\n",
    "    print('오전강수확률 : '+find_am_hm,'%')\n",
    "    find_pm_hm = Wdata.select_one('li>span.point_time.afternoon>span.rain_rate>span.num').text\n",
    "    print('오후강수확률 : '+find_pm_hm,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee3447",
   "metadata": {},
   "source": [
    "##### 내일 날씨 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c74cadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomorrow_weather():\n",
    "    html = requests.get('https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%82%A0%EC%94%A8')\n",
    "    soup = b_s(html.text,'html.parser')\n",
    "    Wdata = soup.find('div', {'class':'weather_box'})\n",
    "    find_t_ct = Wdata.select_one('div.main_info.morning_box>p.info_temperature>span.todaytemp').text\n",
    "    print(\"내일 날씨 : \"+find_t_ct,'℃' )\n",
    "    find_t_dt = Wdata.select_one('div.main_info.morning_box>div.info_data>ul.info_list>li>p').text\n",
    "    print(find_t_dt)\n",
    "    find_t_am_hm = Wdata.select_one('li>span.point_time.morning>span.rain_rate.wet>span.num').text\n",
    "    print('내일강수확률 : ',find_t_am_hm,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e47e1f",
   "metadata": {},
   "source": [
    "##### 미세먼지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7a44e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dust():\n",
    "    html = requests.get('https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%82%A0%EC%94%A8')\n",
    "    soup = b_s(html.text,'html.parser')\n",
    "    Ddata = soup.find('div', {'class':'weather_box'})\n",
    "    find_du = Ddata.select_one('dl.indicator>dd>span.num').text\n",
    "    ev_du = int(find_du.strip('㎍/㎥'))\n",
    "\n",
    "    if ev_du <= 30:\n",
    "        ev_dust = \"좋음\"\n",
    "    elif 30 <ev_du<= 80:\n",
    "        ev_dust = \"보통\"\n",
    "    elif 80 <ev_du<= 150:\n",
    "        ev_dust = \"나쁨\"\n",
    "    else:\n",
    "        ev_dust = \"매우나쁨\"\n",
    "\n",
    "    print(\"미세먼지 : \" + find_du, ev_dust)\n",
    "\n",
    "    find_M_du = Ddata.select('dl.indicator>dd>span.num')[1].text\n",
    "    ev_M_du = int(find_M_du.strip('㎍/㎥'))\n",
    "\n",
    "    if ev_M_du <= 15:\n",
    "        ev_M_dust = \"좋음\"\n",
    "    elif 15 <ev_M_du<= 50:\n",
    "        ev_M_dust = \"보통\"\n",
    "    elif 51 <ev_M_du<= 100:\n",
    "        ev_M_dust = \"나쁨\"\n",
    "    else:\n",
    "        ev_M_dust = \"매우나쁨\"\n",
    "\n",
    "    print(\"초미세먼지 : \" + find_M_du, ev_M_dust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f163e",
   "metadata": {},
   "source": [
    "##### 코로나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "84b7fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corona19():\n",
    "    html = requests.get('https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EC%BD%94%EB%A1%9C%EB%82%98')\n",
    "    soup = b_s(html.text,'html.parser')\n",
    "    html1 = requests.get('http://ncov.mohw.go.kr/')\n",
    "    soup1 = b_s(html1.text,'html.parser')\n",
    "    status = soup1.select_one('div.liveNumOuter>h2>a').text\n",
    "    status = status.split('자세히')[0]\n",
    "    # type(status)\n",
    "    status = status.split(',')\n",
    "    status\n",
    "    print(status)\n",
    "    tsct = soup1.select_one('div.datalist>ul>li>span.subtit').string\n",
    "    tsctn = soup1.select_one('div.datalist>ul>li>span.data').string\n",
    "    print(tsct,':', tsctn)\n",
    "    find_cf = soup.select_one('ul>li.info_01>p.info_num').text\n",
    "    print('누적환자 : ',find_cf,'명')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc76ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c55060",
   "metadata": {},
   "source": [
    "##### 국내증시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "52a6d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_stock():\n",
    "    req = requests.get('https://finance.naver.com/sise/')\n",
    "    html = req.text\n",
    "    soup = b_s(html,'html.parser')\n",
    "\n",
    "    stock_names = soup.select('ul.lst_pop>li>a')\n",
    "#     for stock_name in stock_names:\n",
    "#         print(stock_name.text)\n",
    "\n",
    "    stock_costs = soup.select('ul.lst_pop>li>span')\n",
    "#     for stock_cost in stock_costs:\n",
    "#         print(stock_cost.text)\n",
    "    stock_costs\n",
    "    \n",
    "    stock_vars = soup.select('ul.lst_pop>li>em.bu_p>span.blind')\n",
    "#     for stocks_var in stocks_vars:\n",
    "#         print(stocks_var.string)\n",
    "\n",
    "    stock = pd.DataFrame([stock_names,stock_costs,stock_vars])\n",
    "    stock = stock.transpose()\n",
    "    stock = stock.rename(columns={0:'종목명',1:'현재가',2:'변화'})\n",
    "    return display(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "083af774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>현재가</th>\n",
       "      <th>변화</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[삼성전자]</td>\n",
       "      <td>[79,400]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[카카오게임즈]</td>\n",
       "      <td>[84,500]</td>\n",
       "      <td>[상승]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[카카오]</td>\n",
       "      <td>[160,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[현대차]</td>\n",
       "      <td>[226,000]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[SK하이닉스]</td>\n",
       "      <td>[119,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[휴마시스]</td>\n",
       "      <td>[25,550]</td>\n",
       "      <td>[상승]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[씨젠]</td>\n",
       "      <td>[88,000]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[한국조선해양]</td>\n",
       "      <td>[124,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ARIRANG 고배당주]</td>\n",
       "      <td>[12,180]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[TIGER 200 IT]</td>\n",
       "      <td>[38,345]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              종목명        현재가    변화\n",
       "0          [삼성전자]   [79,400]  [하락]\n",
       "1        [카카오게임즈]   [84,500]  [상승]\n",
       "2           [카카오]  [160,500]  [하락]\n",
       "3           [현대차]  [226,000]  [하락]\n",
       "4        [SK하이닉스]  [119,500]  [하락]\n",
       "5          [휴마시스]   [25,550]  [상승]\n",
       "6            [씨젠]   [88,000]  [하락]\n",
       "7        [한국조선해양]  [124,500]  [하락]\n",
       "8  [ARIRANG 고배당주]   [12,180]  [하락]\n",
       "9  [TIGER 200 IT]   [38,345]  [하락]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "popular_stock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e491e",
   "metadata": {},
   "source": [
    "###### 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc441f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-69715450983a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mheadline_news\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_clickable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mNEWS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-69715450983a>\u001b[0m in \u001b[0;36mNEWS\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://news.naver.com/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Mozilla/5.0 (Windosws NT 6.3; Win64; x64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnews_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mheadline_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.hdline_news>ul.hdline_article_list>li>div.hdline_article_tit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "def NEWS():\n",
    "    url = 'https://news.naver.com/'\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windosws NT 6.3; Win64; x64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "    res = requests.get(url,headers=headers)\n",
    "    news_soup = b_s(res.text,'html.parser')\n",
    "    headline_titles = news_soup.select('div.hdline_news>ul.hdline_article_list>li>div.hdline_article_tit')\n",
    "    headline_title = []\n",
    "    for title in headline_titles:\n",
    "        headline_title.append(title.text.strip())\n",
    "    headline_title\n",
    "\n",
    "    headline_links = news_soup.select('div.hdline_news>ul.hdline_article_list>li>div.hdline_article_tit>a')\n",
    "    headline_link = []\n",
    "    for link in headline_links:\n",
    "        headline_link.append(\"https://news.naver.com\"+link.get('href'))\n",
    "    headline_link\n",
    "\n",
    "    headline_news = pd.DataFrame([headline_title,headline_link]).T\n",
    "    headline_news.rename(columns = {0:'Headline News Title',1:'Link'},inplace=True)\n",
    "    # headline_news['Link'] = headline_news['Link'].apply(lambda x : make_hyper(x))\n",
    "#     folder_path = os.getcwd()\n",
    "#     headline_news.to_excel('Today News.xlsx')\n",
    "#     os.startfile(folder_path)\n",
    "\n",
    "\n",
    "\n",
    "    # def make_hyper(value):\n",
    "    #     return '=HYPERLINK(\"%s\")' % (value.format(value))\n",
    "    # def make_clickable(val):\n",
    "    #     return '<a href=\"{}\">{}</a>'.format(val,val)\n",
    "    return headline_news.style.format(make_clickable)\n",
    "\n",
    "NEWS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7508b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63417ef1",
   "metadata": {},
   "source": [
    "##### food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dfbb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_foods = \"부대찌개,아구찜,해물탕,칼국수,수제비,짬뽕,우동,치킨,국밥,김치부침개,두부김치,파전\".split(',')\n",
    "mdhigh_foods = \"콩나물국밥,고등어,굴,쌀국수,마라탕\".split(',')\n",
    "hightemp_foods =\"냉면,삼계탕,밀면,소바,스파게티,베이글,치킨\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1377db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 인증\n",
    "# https://developers.naver.com/apps\n",
    "# 해당 사이트에서 로그인 후 \"Cliend ID\"와 \"Client Secret\"을 얻어오세요\n",
    "ncreds = {\n",
    "    \"client_id\": \"IS7Lmhp7lT6z4uFNjEG5\",      \n",
    "    \"client_secret\" : \"8LtHME2zTz\"\n",
    "}\n",
    "nheaders = {\n",
    "    \"X-Naver-Client-Id\" : ncreds.get('IS7Lmhp7lT6z4uFNjEG5'),\n",
    "    \"X-Naver-Client-Secret\" : ncreds.get('8LtHME2zTz')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40375aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼계탕', '소바', '베이글', '스파게티', '밀면', '냉면', '치킨']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get('https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%82%A0%EC%94%A8')\n",
    "soup = b_s(html.text,'html.parser')\n",
    "Wdata = soup.find('div', {'class':'weather_box'})\n",
    "find_ft = Wdata.select_one('span.sensible>em>span.num').text\n",
    "foods_list = None\n",
    "\n",
    "if int(find_ft) >=   25:\n",
    "    foods_list = random.sample(hightemp_foods,k=len(hightemp_foods))\n",
    "elif 19 <= int(find_ft) < 25:\n",
    "    foods_list = random.sample(mdhigh_foods, k=len(mdhigh_foods))\n",
    "elif int(find_ft) < 19:\n",
    "    foods_list = random.sample(rain_foods, k=len(rain_foods))\n",
    "else:\n",
    "    foods_list = ['']\n",
    "    \n",
    "foods_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a01863a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-4638a52a756f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m21\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_ft\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mrecommands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# 경우 1,2 처리\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "# urllib.parse.quote(query) URL에서 검색어를 인코딩하기 위한 라이브러리\n",
    "\n",
    "# 네이버 지역 검색 주소\n",
    "naver_local_url = \"https://openapi.naver.com/v1/search/local.json?\"\n",
    "\n",
    "# 검색에 사용될 파라미터\n",
    "# 정렬 sort : 리뷰순(comment)\n",
    "# 검색어 query : 인코딩된 문자열\n",
    "params_format = \"sort=comment&query=\"\n",
    "\n",
    "# 위치는 사용자가 사용할 지역으로 변경가능\n",
    "location = \"이대역\"\n",
    "\n",
    "# 추천된 맛집을 담을 리스트\n",
    "recommands = []\n",
    "for food in foods_list:\n",
    "    # 검색어 지정\n",
    "    query = location + \" \" + food + \" 맛집\"\n",
    "    # 지역검색 요청 파라메터 설정\n",
    "    params = \"sort=comment\" \\\n",
    "              + \"&query=\" + query \\\n",
    "              + \"&display=\" + '5'\n",
    "    \n",
    "    # 검색\n",
    "    # headers : 네이버 인증 정보\n",
    "    res = requests.get(naver_local_url + params, headers=nheaders)\n",
    "    \n",
    "    # 맛집 검색 결과\n",
    "    result_list = res.json().get('items')\n",
    "\n",
    "    # 경우 3 처리\n",
    "    # 맛집 검색 결과에서 가장 상위 3개를 가져옴\n",
    "    if 21 <= int(find_ft) <= 30:\n",
    "        for i in range(0,3):\n",
    "            recommands.append(result_list[i])\n",
    "        break\n",
    "    # 경우 1,2 처리\n",
    "    # 해당 음식 검색 결과에서 가장 상위를 가져옴\n",
    "    if result_list:\n",
    "        recommands.append(result_list[0])\n",
    "        # 3개를 찾았다면 검색 중단\n",
    "        if len(recommands) >= 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c38e0f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024dae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce3254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0c82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c23e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b2c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff98174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73731ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df9bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891f543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b9a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2945e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d71e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46967726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bebfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d293244",
   "metadata": {},
   "source": [
    "##### 길찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ed8f5",
   "metadata": {},
   "source": [
    "# 모두 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "618f79c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "         2021-07-12-Monday 의 리마인더입니다.\n",
      "################################################## \n",
      "\n",
      "\n",
      "1.날씨\n",
      "**************************************************\n",
      "                        오늘\n",
      "--------------------------------------------------\n",
      "현재위치 : 경기도 김포시 김포본동 ℃\n",
      "현재온도 : 25 ℃\n",
      "최고온도 : 32 ℃\n",
      "최저온도 : 24 ℃\n",
      "체감온도 : 27 ℃\n",
      "흐림, 어제보다 1˚ 높아요\n",
      "오전강수확률 : 60 %\n",
      "오후강수확률 : 20 %\n",
      "**************************************************\n",
      "<미세먼지>\n",
      "--------------------------------------------------\n",
      "미세먼지 : 10㎍/㎥ 좋음\n",
      "초미세먼지 : 9㎍/㎥ 좋음\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "                 내일 날씨입니다.\n",
      "--------------------------------------------------\n",
      "내일 날씨 : 25 ℃\n",
      "흐림\n",
      "내일강수확률 :  60 %\n",
      "\n",
      "\n",
      "2.코로나19 현재 상황\n",
      "************************************************** \n",
      "\n",
      "\n",
      "['환자 현황(7.11. 00시 기준', \" '20.1.3. 이후 누계)\"]\n",
      "국내발생 : 1,280\n",
      "누적환자 :  168,046 명\n",
      "3.인기 국내증시 현재 상황\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>현재가</th>\n",
       "      <th>변화</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[삼성전자]</td>\n",
       "      <td>[79,400]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SK하이닉스]</td>\n",
       "      <td>[119,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[씨젠]</td>\n",
       "      <td>[88,000]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[코오롱인더우]</td>\n",
       "      <td>[33,750]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[카카오]</td>\n",
       "      <td>[160,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[한국조선해양]</td>\n",
       "      <td>[124,500]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[두산중공업]</td>\n",
       "      <td>[26,100]</td>\n",
       "      <td>[상승]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[엑세스바이오]</td>\n",
       "      <td>[34,400]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[DL이앤씨우]</td>\n",
       "      <td>[80,000]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[우리금융지주]</td>\n",
       "      <td>[11,150]</td>\n",
       "      <td>[하락]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        종목명        현재가    변화\n",
       "0    [삼성전자]   [79,400]  [하락]\n",
       "1  [SK하이닉스]  [119,500]  [하락]\n",
       "2      [씨젠]   [88,000]  [하락]\n",
       "3  [코오롱인더우]   [33,750]  [하락]\n",
       "4     [카카오]  [160,500]  [하락]\n",
       "5  [한국조선해양]  [124,500]  [하락]\n",
       "6   [두산중공업]   [26,100]  [상승]\n",
       "7  [엑세스바이오]   [34,400]  [하락]\n",
       "8  [DL이앤씨우]   [80,000]  [하락]\n",
       "9  [우리금융지주]   [11,150]  [하락]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. News?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b6729_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Headline News Title</th>        <th class=\"col_heading level0 col1\" >Link</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b6729_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b6729_row0_col0\" class=\"data row0 col0\" ><a href=\"與 “부끄러운 줄 알라”…野 김재원 “선거인단 돼 달라며”\">與 “부끄러운 줄 알라”…野 김재원 “선거인단 돼 달라며”</a></td>\n",
       "                        <td id=\"T_b6729_row0_col1\" class=\"data row0 col1\" ><a href=\"https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=100&oid=025&aid=0003117307\">https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=100&oid=025&aid=0003117307</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6729_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b6729_row1_col0\" class=\"data row1 col0\" ><a href=\"신규 확진자 1100명대 예상…오늘부터 수도권 거리두기 4단계\">신규 확진자 1100명대 예상…오늘부터 수도권 거리두기 4단계</a></td>\n",
       "                        <td id=\"T_b6729_row1_col1\" class=\"data row1 col1\" ><a href=\"https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=102&oid=025&aid=0003117404\">https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=102&oid=025&aid=0003117404</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6729_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b6729_row2_col0\" class=\"data row2 col0\" ><a href=\"아이티 영부인, 피격 후 첫 육성…“말할 기회도 없이 총 난사”\">아이티 영부인, 피격 후 첫 육성…“말할 기회도 없이 총 난사”</a></td>\n",
       "                        <td id=\"T_b6729_row2_col1\" class=\"data row2 col1\" ><a href=\"https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=104&oid=020&aid=0003369379\">https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=104&oid=020&aid=0003369379</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6729_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b6729_row3_col0\" class=\"data row3 col0\" ><a href=\"G20 '디지털세' 합의···131개국서 稅 177조 추가로 걷힐 듯\">G20 '디지털세' 합의···131개국서 稅 177조 추가로 걷힐 듯</a></td>\n",
       "                        <td id=\"T_b6729_row3_col1\" class=\"data row3 col1\" ><a href=\"https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=101&oid=011&aid=0003935087\">https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=101&oid=011&aid=0003935087</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b6729_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b6729_row4_col0\" class=\"data row4 col0\" ><a href=\"이재명 '김건희 검증' 거리두기에 與추격자들 일제히 공세(종합)\">이재명 '김건희 검증' 거리두기에 與추격자들 일제히 공세(종합)</a></td>\n",
       "                        <td id=\"T_b6729_row4_col1\" class=\"data row4 col1\" ><a href=\"https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=100&oid=001&aid=0012517664\">https://news.naver.com/main/read.naver?mode=LSD&mid=shm&sid1=100&oid=001&aid=0012517664</a></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cb1d7b46a0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('#'*50)\n",
    "print('        ',today,\"의 리마인더입니다.\")\n",
    "print('#'*50,'\\n\\n')\n",
    "print('1.날씨')\n",
    "print('*'*50)\n",
    "print(\"                        오늘\")\n",
    "print('-'*50)\n",
    "today_weather()\n",
    "print('*'*50)\n",
    "print(\"<미세먼지>\")\n",
    "print('-'*50)\n",
    "dust()\n",
    "print('\\n')\n",
    "print('-'*50)\n",
    "print(\"                 내일 날씨입니다.\")\n",
    "print('-'*50)\n",
    "tomorrow_weather()\n",
    "print('\\n')\n",
    "print('2.코로나19 현재 상황')\n",
    "print('*'*50,'\\n\\n')\n",
    "corona19()\n",
    "print('3.인기 국내증시 현재 상황')\n",
    "print('*'*50)\n",
    "popular_stock()\n",
    "\n",
    "print('4. News')\n",
    "NEWS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "1fea43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auto_news():\n",
    "#     URL = 'https://news.naver.com/'\n",
    "#     res = req.urlopen(URL).read()\n",
    "#     news_soup = b_s(res,'html.parser')\n",
    "    \n",
    "#     #list 생성\n",
    "#     news_list = []\n",
    "#     new_news = []\n",
    "#     news_link = []\n",
    "    \n",
    "#     #헤드라인 \n",
    "#     news_title = news_soup.select('div#today_main_news>div.heline|_news>ul>li>div.hdline_article_tit')\n",
    "#     news_links = news_soup.select('div#today_main_news>div.hdline_news>ul>li>div.hdline_article_tit>a')\n",
    "    \n",
    "#     #리스트별 추가\n",
    "#     for news in news_title:\n",
    "#         new_news.append(news.text.strip())\n",
    "        \n",
    "#     for link in news_link:\n",
    "#         news_link.append(\"https://naver.com\"+link.get('href'))\n",
    "    \n",
    "#     #담기    \n",
    "#     for i in range(len(new_news)):\n",
    "#         news_list.append([[new_news[i],news_link[i]]])\n",
    "\n",
    "#     #시간별\n",
    "#     time = dt.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "#     #DF\n",
    "#     news_data = pd.DataFrame(news_list)\n",
    "#     news_data.columns = [time+'Title',\"Link\"]\n",
    "#     news_data.to_csv('news_headline_today.csv',mode = 'a',encoding='euc-kr')\n",
    "\n",
    "\n",
    "# def find_News():\n",
    "#     #엑셀 저장용\n",
    "#     date=str(dt.now())\n",
    "\n",
    "#     query = input('검색 키워드를 입력하세요 : ')\n",
    "#     news_num = int(input('총 필요한 뉴스기사 수를 입력해주세요(숫자만 입력) : '))\n",
    "#     query = query.replace(' ', '+')\n",
    "\n",
    "#     #URL 확인\n",
    "#     news_url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
    "#     req = requests.get(news_url.format(query))\n",
    "#     soup = b_s(req.text, 'html.parser')\n",
    "\n",
    "\n",
    "#     news_dict = {}\n",
    "#     idx = 0\n",
    "#     cur_page = 1\n",
    "\n",
    "#     print()\n",
    "#     print('크롤링 중...')\n",
    "\n",
    "#     while idx < news_num:\n",
    "#     ### 네이버 뉴스 웹페이지 구성이 바뀌어 태그명, class 속성 값 등을 수정함(20210126) ###\n",
    "\n",
    "#         table = soup.find('ul',{'class' : 'list_news'})\n",
    "#         li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
    "#         area_list = [li.find('div', {'class' : 'news_area'}) for li in li_list]\n",
    "#         a_list = [area.find('a', {'class' : 'news_tit'}) for area in area_list]\n",
    "\n",
    "#         for n in a_list[:min(len(a_list), news_num-idx)]:\n",
    "#             news_dict[idx] = {'title' : n.get('title'),\n",
    "#                               'url' : n.get('href') }\n",
    "#             idx += 1\n",
    "\n",
    "#         cur_page += 1\n",
    "\n",
    "#         pages = soup.find('div', {'class' : 'sc_page_inner'})\n",
    "#         next_page_url = [p for p in pages.find_all('a') if p.text == str(cur_page)][0].get('href')\n",
    "\n",
    "#         req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
    "#         soup = b_s(req.text, 'html.parser')\n",
    "\n",
    "#     print('크롤링 완료')\n",
    "\n",
    "#     print('데이터프레임 변환')\n",
    "#     news_df = pd.DataFrame(news_dict).T\n",
    "\n",
    "#     folder_path = os.getcwd()\n",
    "#     xlsx_file_name = '네이버뉴스_{}_{}.xlsx'.format(query, date)\n",
    "\n",
    "#     news_df.to_excel(xlsx_file_name)\n",
    "\n",
    "#     print('엑셀 저장 완료 | 경로 : {}\\\\{}'.format(folder_path, xlsx_file_name))\n",
    "#     os.startfile(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a0fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
