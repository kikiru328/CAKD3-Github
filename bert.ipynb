{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1SnwOX2Twmx6jch2_zn-1b4mJ9-dGA_pX",
      "authorship_tag": "ABX9TyPjn7XgHjf77QttOPcCN5Wq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kikiru328/CAKD3-Github/blob/main/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80nIjT6KSjav"
      },
      "source": [
        "https://huggingface.co/transformers/\n",
        "\n",
        "- HuggingFace는 자연어 처리 인공지능 모델에서, BERT 모델 같은 트랜스포머 모델들을 쉽게 다룰 수 있게 해주는 패키지입니다.\n",
        "- 기본적으로 pytorch 기반으로 만들어져 있지만, 텐서플로우 2.0에서도 본 패키지 사용 가능합니다.\n",
        "- 텐서플로우 2.0은 기존 케라스를 포함하고 있기 때문에, 기존 텐서플로우나 케라스에 익숙하신 분들이 쉽게 사용할 수 있습니다.\n",
        "- 텐서플로우 2.0 기반의 huggingface 사용 방법을 네이버 영화 긍부정 분석을 실슴하면서 배워 보도록 하겠습니다.\n",
        "\n",
        "* 인스톨\n",
        "huggingface 패키지를 Colab에 설치합니다.\n",
        "\n",
        "- 허깅페이스는 트랜스포머를 기반으로 하는 다양한 모델 (transformer.models)과 학습 스크립트(transformer.Trainer)를 구현해 놓은 모듈이다. \n",
        "- 원래는 파이토치로 layer, model등을 선언해주고 학습 스크립트도 전부 구현해야 하지만, 허깅 페이스를 사용하면 이런 수고를 덜 수 있다.\n",
        "- 정리하면 허깅페이스라는 회사가 만든 transformers 패키지가 있고, 일반적인 파이토치 구현체의 layer.py, model.py이 transfomer.models 에 train.py가 transformer.Trainer에 대응된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvfKaPNqUgi0"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgIDx1lMVfk1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uR5IawbWI7g",
        "outputId": "ca627f41-2349-4796-e1eb-81791d56b8fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMyhOz-JWm0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61063c5-28d6-417e-d4be-37308e0c1088"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 23.89 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApqINIAuXWRW",
        "outputId": "d142f823-bf7b-4a6d-88ad-02e8249d73a2"
      },
      "source": [
        "os.listdir('nsmc')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['code',\n",
              " 'README.md',\n",
              " 'raw',\n",
              " '.git',\n",
              " 'ratings.txt',\n",
              " 'ratings_train.txt',\n",
              " 'synopses.json',\n",
              " 'ratings_test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "xKP5eNUCXYmg",
        "outputId": "3fddb085-c87e-49c5-edf1-6e4fe40933a6"
      },
      "source": [
        "train = pd.read_table('nsmc/' + 'ratings_train.txt')\n",
        "test = pd.read_table('nsmc/' + 'ratings_test.txt')\n",
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbjdegBTXtJ5"
      },
      "source": [
        "# bert input\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shyrh4OEX5Qk",
        "outputId": "2fd12ca9-f3a3-44c1-c506-67c546b5979c"
      },
      "source": [
        "tokenizer.encode('보는내내 그대로 들어맞는 예측 카리스마 없는 악역')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 9356,\n",
              " 11018,\n",
              " 31605,\n",
              " 31605,\n",
              " 110589,\n",
              " 71568,\n",
              " 118913,\n",
              " 11018,\n",
              " 9576,\n",
              " 119281,\n",
              " 9786,\n",
              " 79940,\n",
              " 23811,\n",
              " 40364,\n",
              " 9520,\n",
              " 23160,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL0n1oXQYQKc",
        "outputId": "43656394-b120-41c9-a66f-4a58d3adc315"
      },
      "source": [
        "tokenizer.tokenize('보는내내 그대로 들어맞는 예측 카리스마 없는 악역')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['보',\n",
              " '##는',\n",
              " '##내',\n",
              " '##내',\n",
              " '그대로',\n",
              " '들어',\n",
              " '##맞',\n",
              " '##는',\n",
              " '예',\n",
              " '##측',\n",
              " '카',\n",
              " '##리스',\n",
              " '##마',\n",
              " '없는',\n",
              " '악',\n",
              " '##역']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZn38EdhYkGk",
        "outputId": "7a9bc755-7b1e-4106-e3e9-624a0ae373df"
      },
      "source": [
        "print( tokenizer.encode('전율을 일으키는 영화. 다시 보고 싶은 영화', max_length = 129 ,pad_to_max_length = True))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 9495, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1jHHs7LZF6t",
        "outputId": "6e049d53-3164-4803-9539-b687f4a7a945"
      },
      "source": [
        "# mask 인풋\n",
        "valid_num = len(tokenizer.encode('전율을 일으키는 영화. 다시 보고 싶은 영화'))\n",
        "print(valid_num * [1] + (128 -valid_num) * [0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZawCqrmVZxbU"
      },
      "source": [
        "# 네이버 영화 평가 무장들을 버트 인풋으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh69HyOWaXRo"
      },
      "source": [
        "def convert_data(data_df):\n",
        "  global tokenizer\n",
        "\n",
        "  SEQ_LEN= 128  # bert 인풋의 길이 \n",
        "\n",
        "  tokens, masks, segments, targets = [],[],[],[]\n",
        "\n",
        "  for i in tqdm(range(len(data_df))):\n",
        "    token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length= SEQ_LEN, truncation=True,padding='max_length')\n",
        "\n",
        "    num_zeros= token.count(0)\n",
        "    mask = [1]* (SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "\n",
        "    segment = [0] *SEQ_LEN\n",
        "\n",
        "    tokens.append(token)\n",
        "    masks.append(mask)\n",
        "    segments.append(segment)\n",
        "\n",
        "    targets.append(data_df[LABEL_COLUMN][i])\n",
        "\n",
        "  tokens= np.array(tokens)\n",
        "  masks= np.array(masks)\n",
        "  segments= np.array(segments)\n",
        "  targets= np.array(targets)\n",
        "\n",
        "  return  [tokens,masks, segments], targets\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqrAChjPckhV",
        "outputId": "7f7791cd-3e0e-4624-fc42-0c077b0602c8"
      },
      "source": [
        "def load_data(pandas_dataframe):\n",
        "  data_df = pandas_dataframe\n",
        "  data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "  data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "  data_x, data_y = convert_data(data_df)\n",
        "  return data_x, data_y\n",
        "\n",
        "\n",
        "SEQ_LEN= 128\n",
        "BATCH_SIZE = 20\n",
        "DATA_COLUMN = 'document'\n",
        "LABEL_COLUMN= 'label'\n",
        "\n",
        "train_x, train_y= load_data(train)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150000/150000 [01:00<00:00, 2465.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U282uGpde64",
        "outputId": "2fca8238-d7ab-450e-f99e-7bfe46710355"
      },
      "source": [
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:19<00:00, 2500.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sjWSJmnehan",
        "outputId": "29c2e2b1-94a5-4b7e-a0bd-ac7dfb3d7060"
      },
      "source": [
        "test_y"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJbYxSlweiqd"
      },
      "source": [
        "#### 버트를 활용한 감성분석 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoT0tlFCerer",
        "outputId": "dca4c5d6-3fa0-4623-de4e-78b08fa062b1"
      },
      "source": [
        "# TPU 객체지정\n",
        "TPU = True\n",
        "if TPU :\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.204.170:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.204.170:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-8SDldfHee"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}